{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marissa\\Documents\\Portfolio\\Education project\n",
      "['.ipynb_checkpoints', 'adm2014.csv', 'CollegeScorecardDataDictionary-09-08-2015.csv', 'CollegeScorecard_Raw_Data (2)', 'CollegeScorecard_Raw_Data (2).zip', 'data-sources', 'exploring_scorecard_data.md', 'First libpgm.ipynb', 'firstgraph.txt', 'g20145ak.txt', 'Integrated_Postsecondary_Education_Data_System_20132014.csv', 'merged_2011_PP.csv', 'merged_2012_PP.csv', 'merged_2013_PP.csv', 'Objective Hypothesis.docx', 'Scorecard_dict.csv', 'Scorecard_dict.txt', 'Scorecard_v1.csv', 'Second pgm.ipynb', 'US Zip Codes from 2013 Government Data']\n"
     ]
    }
   ],
   "source": [
    "import libpgm\n",
    "import os\n",
    "import pandas as pd\n",
    "print os.getcwd()\n",
    "print os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0        Non-degree-granting\\n']\n",
      "['1        Certificate degree\\n']\n",
      "['2        Associate degree\\n']\n",
      "[\"3        Bachelor's degree\\n\"]\n",
      "['4        Graduate degree\\n']\n",
      "['0        Not classified\\n']\n",
      "['1        Predominantly certificate-degree granting\\n']\n",
      "[\"2        Predominantly associate's-degree granting\\n\"]\n",
      "[\"3        Predominantly bachelor's-degree granting\\n\"]\n",
      "['4        Entirely graduate-degree granting\\n']\n"
     ]
    }
   ],
   "source": [
    "## Get clean data\n",
    "map_variables = {}\n",
    "clean = pd.read_csv(\"Scorecard_v1.csv\")\n",
    "dict_file = open(\"Scorecard_dict.txt\", \"r\")\n",
    "for line in dict_file:\n",
    "    test = line.split(\"|\")\n",
    "    try:\n",
    "        map_variables[test[0]] = test[1]\n",
    "    except:\n",
    "        print test\n",
    "dict_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: University of Alabama at Birmingham\n",
      "Admissions: 0.7223\n",
      "ACTCM25 21.0\n",
      "ACTCM75 27.0\n",
      "ACTCMMID 24.0\n",
      "ACTEN25 21.0\n",
      "ACTEN75 28.0\n",
      "ACTENMID 25.0\n",
      "ACTMT25 20.0\n",
      "ACTMT75 26.0\n",
      "ACTMTMID 23.0\n",
      "SATMT25 500.0\n",
      "SATMT75 640.0\n",
      "SATMTMID 570.0\n",
      "SATVR25 500.0\n",
      "SATVR75 630.0\n",
      "SATVRMID 565.0\n",
      "SAT_AVG 1107.0\n",
      "SAT_AVG_ALL 1107.0\n"
     ]
    }
   ],
   "source": [
    "## Choose university as the first row of clean data\n",
    "\n",
    "data = clean.ix[1,]\n",
    "print \"Name:\", data[\"INSTNM\"]\n",
    "print \"Admissions:\", data[\"ADM_RATE\"]\n",
    "for var in sorted(data.index):\n",
    "    if \"SAT\" in var:\n",
    "        print var, data[var.strip()]\n",
    "    if \"ACT\" in var:\n",
    "        print var, data[var.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read in SAT distributions\n",
    "SAT = pd.read_csv(\"data-sources/SAT_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D 0.521009\n",
      "C 0.213985\n",
      "B 0.150654\n",
      "A 0.114352\n"
     ]
    }
   ],
   "source": [
    "## Calculate conditional probabilities\n",
    "# Split into quantiles - \"A\", \"B\", \"C\", \"D\"\n",
    "P = {}\n",
    "P[\"quant | admit\"] = 0.25\n",
    "P[\"admit\"] = data[\"ADM_RATE\"]\n",
    "d_cut = data[\"SATMT25\"] + data[\"SATVR25\"]\n",
    "c_cut = data[\"SATMTMID\"] + data[\"SATVRMID\"]\n",
    "b_cut = data[\"SATMT75\"] + data[\"SATVR75\"]\n",
    "\n",
    "def find_percentile(cutoff, dataframe, scores_column = \"New SAT Score\", percentiles_column = \"Percentile\"):\n",
    "    min_val = min(abs(dataframe[scores_column] - cutoff))\n",
    "    temp = dataframe[abs((dataframe[scores_column] - cutoff)) <= min_b][percentiles_column]\n",
    "    if(len(temp) == 1):    \n",
    "        P = float(temp)/100\n",
    "    else:\n",
    "        P = float(sum(temp)/2.0)/100\n",
    "    return P\n",
    "\n",
    "\n",
    "P[\"D\"] = find_percentile(d_cut, SAT)\n",
    "print \"D\", P[\"D\"]\n",
    "\n",
    "P[\"C\"] = find_percentile(c_cut, SAT) - P[\"D\"]\n",
    "print \"C\", P[\"C\"]\n",
    "\n",
    "P[\"B\"] = find_percentile(b_cut, SAT)   - P[\"D\"] - P[\"C\"]\n",
    "print \"B\", P[\"B\"]\n",
    "P[\"A\"] = 1.0 - P[\"B\"] - P[\"C\"] - P[\"D\"]\n",
    "print \"A\", P[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit | A =  0.999\n",
      "admit | B =  0.999\n",
      "admit | C =  0.84386756081\n",
      "admit | D =  0.346587103102\n"
     ]
    }
   ],
   "source": [
    "## Apply Bayes rule\n",
    "\n",
    "P[\"admit|A\"] = min(P[\"quant | admit\"] * P[\"admit\"] / P[\"A\"], 0.999)\n",
    "print \"admit | A = \", P[\"admit|A\"]\n",
    "P[\"admit|B\"] = min(P[\"quant | admit\"] * P[\"admit\"] / P[\"B\"], 0.999)\n",
    "print \"admit | B = \", P[\"admit|B\"]\n",
    "P[\"admit|C\"] = min(P[\"quant | admit\"] * P[\"admit\"] / P[\"C\"], 0.999)\n",
    "print \"admit | C = \", P[\"admit|C\"]\n",
    "P[\"admit|D\"] = min(P[\"quant | admit\"] * P[\"admit\"] / P[\"D\"], 0.999)\n",
    "print \"admit | D = \", P[\"admit|D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'SAT_quant', u'Admitted']]\n",
      "[u'SAT_quant', u'Admitted']\n",
      "Admitted     6244\n",
      "SAT_quant    6244\n",
      "dtype: int64\n",
      "\n",
      "SAT_quant       A       B       C       D\n",
      "Admitted                                 \n",
      "no            NaN     2.0   354.0  3400.0\n",
      "yes        1108.0  1491.0  1829.0  1816.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from libpgm.nodedata import NodeData\n",
    "from libpgm.graphskeleton import GraphSkeleton\n",
    "from libpgm.discretebayesiannetwork import DiscreteBayesianNetwork\n",
    "\n",
    "rate = 0.5\n",
    "filename = \"firstgraph.txt\"\n",
    "\n",
    "\n",
    "\n",
    "myfile = open(filename, \"w\")\n",
    "ftext = '''{\n",
    "\t\"V\": [\"SAT_quant\", \"Admitted\"],\n",
    "\t\"E\": [[\"SAT_quant\", \"Admitted\"]],\n",
    "\t\"Vdata\": {\n",
    "\t\t\"Admitted\": {\n",
    "\t\t\t\"ord\": 1,\n",
    "\t\t\t\"numoutcomes\": 2,\n",
    "\t\t\t\"vals\": [\"yes\", \"no\"],\n",
    "\t\t\t\"parents\": [\"SAT_quant\"],\n",
    "\t\t\t\"children\": None,\n",
    "\t\t\t\"cprob\": {\n",
    "\t\t\t\t\"['A']\": [''' + str(P[\"admit|A\"]) + \",\" + str(1.0 - P[\"admit|A\"]) + '''],\n",
    "\t\t\t\t\"['B']\": ['''  + str(P[\"admit|B\"]) + \",\" +str(1.0 - P[\"admit|B\"]) + '''],\n",
    "\t\t\t\t\"['C']\": [''' + str(P[\"admit|C\"]) + \",\" + str(1.0 - P[\"admit|C\"]) + '''],\n",
    "\t\t\t\t\"['D']\": [''' + str(P[\"admit|D\"]) + \",\" +str(1.0 - P[\"admit|D\"]) + ''']\n",
    "\t\t\t}\n",
    "\t\t},\n",
    "\t\t\"SAT_quant\": {\n",
    "\t\t\t\"ord\": 0,\n",
    "\t\t\t\"numoutcomes\": 4,\n",
    "\t\t\t\"vals\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "\t\t\t\"parents\": None,\n",
    "\t\t\t\"children\": [\"Admitted\"],\n",
    "\t\t\t\"cprob\":  [''' + str(P[\"A\"]) +\",\" + str(P[\"B\"])  +\",\" + str(P[\"C\"])  +\",\" + str(P[\"D\"]) + ''']\n",
    "\t\t}\n",
    "    }\n",
    "}'''\n",
    "ftext = ftext.replace('\\t\\n ', '')\n",
    "ftext = ftext.replace(':', ': ')\n",
    "ftext = ftext.replace(',', ', ')\n",
    "ftext = ftext.replace('None', 'null')\n",
    "\n",
    "# load nodedata and graphskeleton\n",
    "nd = NodeData()\n",
    "skel = GraphSkeleton()\n",
    "\n",
    "myfile.write(ftext)\n",
    "myfile.close()\n",
    "\n",
    "\n",
    "nd.load(filename)\n",
    "skel.load(filename)\n",
    "\n",
    "# topologically order graphskeleton\n",
    "skel.toporder()\n",
    "print skel.E\n",
    "print skel.V\n",
    "# load bayesian network\n",
    "bn = DiscreteBayesianNetwork(skel, nd)\n",
    "\n",
    "# sample \n",
    "result = bn.randomsample(10000)\n",
    "\n",
    "#print result\n",
    "df = pd.DataFrame.from_dict(result)\n",
    "print df[df[\"Admitted\"] == \"yes\"].count()\n",
    "print \"\"\n",
    "print df.pivot_table(index = [\"Admitted\"], columns = [\"SAT_quant\"], aggfunc = len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
